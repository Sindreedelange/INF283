{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Implementing Decision Trees </center>\n",
    "## <center> INF283 - Project 1 </center>\n",
    "### <center> Sindre E. de Lange </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data in order to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'golearn'...\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/sjwhitworth/golearn.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['articles.csv', 'c45-numeric.csv', 'chim.csv', 'exam.csv', 'exams.csv', 'house-votes-84.csv', 'iris.arff', 'iris.csv', 'iris_binned.csv', 'iris_headers.csv', 'iris_headers_subset.csv', 'iris_sorted_asc.csv', 'iris_sorted_desc.csv', 'mnist_test.csv', 'mnist_train.csv', 'randomdata.csv', 'sources.txt', 'tennis.csv', 'weather.arff']\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = \"golearn/examples/datasets/\"\n",
    "print(os.listdir(DATASET_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tennis_dataset = \"tennis.csv\"\n",
    "dataset_tennis = pd.read_csv(DATASET_PATH + tennis_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windy</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunny</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sunny</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overcast</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rainy</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rainy</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    outlook  temp humidity  windy play\n",
       "0     sunny   hot     high  False   no\n",
       "1     sunny   hot     high   True   no\n",
       "2  overcast   hot     high  False  yes\n",
       "3     rainy  mild     high  False  yes\n",
       "4     rainy  cool   normal  False  yes"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tennis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14 entries, 0 to 13\n",
      "Data columns (total 5 columns):\n",
      "outlook     14 non-null object\n",
      "temp        14 non-null object\n",
      "humidity    14 non-null object\n",
      "windy       14 non-null bool\n",
      "play        14 non-null object\n",
      "dtypes: bool(1), object(4)\n",
      "memory usage: 542.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "dataset_tennis.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windy</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>sunny</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       outlook  temp humidity  windy play\n",
       "count       14    14       14     14   14\n",
       "unique       3     3        2      2    2\n",
       "top      sunny  mild     high  False  yes\n",
       "freq         5     6        7      8    9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tennis.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate learning features and target features\n",
    "X = dataset_tennis.drop(['play'], axis=1)\n",
    "y = dataset_tennis['play']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_copy = X\n",
    "y_copy = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columns in X:\n",
    "    X_copy[columns], unique_x = pd.factorize(X[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_copy, unique_y = pd.factorize(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    outlook  temp  humidity  windy\n",
      "0         0     0         0      0\n",
      "1         0     0         0      1\n",
      "2         1     0         0      0\n",
      "3         2     1         0      0\n",
      "4         2     2         1      0\n",
      "5         2     2         1      1\n",
      "6         1     2         1      1\n",
      "7         0     1         0      0\n",
      "8         0     2         1      0\n",
      "9         2     1         1      0\n",
      "10        0     1         1      1\n",
      "11        1     1         0      1\n",
      "12        1     0         1      0\n",
      "13        2     1         0      1\n",
      "(14, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_copy)\n",
    "print(X_copy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 1 0 1 0 1 1 1 1 1 0]\n",
      "(14,)\n"
     ]
    }
   ],
   "source": [
    "print(y_copy)\n",
    "print(y_copy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_copy, y_copy, test_size=0.3, random_state=42)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for verifying the model *check*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implement the ID3 algorithm from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(p):\n",
    "    \"\"\"Calculate the entropy for a given fraction\"\"\"\n",
    "    if p!=0:\n",
    "        return -p * np.log2(p)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy_system(data):\n",
    "    \"\"\"Calculates the entropy of the system\n",
    "    Data is the target variable\"\"\"\n",
    "    tot_len = len(data)\n",
    "    unique, counts = np.unique(data, return_counts=True)\n",
    "    dic = dict(zip(unique, counts))\n",
    "    entropy = 0\n",
    "    for key, value in dic.items():\n",
    "        entropy += calc_entropy(value/tot_len)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def calc_entropy_dataset(data, target_variable):\n",
    "    X = data.drop([target_variable], axis=1)\n",
    "    y = data[target_variable]\n",
    "    tot_num_occurences = len(y)\n",
    "    # TODO: target_variable_entropy/entropy of the whole system\n",
    "    \n",
    "    entropy_system = calc_entropy_system(y)\n",
    "    X_y_zip = {}\n",
    "    for columns in X:\n",
    "        # Map each value in each column to their \"outcome\"/target variable\n",
    "        X_y_zip[columns] = data[[columns, target_variable]].apply(tuple, axis=1)\n",
    "    each_feature_w_entropy = calc_entropy_feature(X_y_zip, tot_num_occurences)\n",
    "    \n",
    "\n",
    "    return calc_entropy_all_branches(each_feature_w_entropy, entropy_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy_feature(X_y_zip, tot_num_occurences):\n",
    "    \"\"\"Calcalutes the entropy for each feature in a dataset.\n",
    "    Assumes that all unique columns are zipped with the target variable.\n",
    "    Returns a dictionary on the format \n",
    "        {'column feature': \n",
    "            {unique value: [\n",
    "                number of times this value occured in the set\n",
    "                number of values in the set\n",
    "                entropy when this value occured in the set\n",
    "            ], ... }}\"\"\"\n",
    "    columns_entropy = {}\n",
    "    for feature in X_y_zip:\n",
    "        # Get unique variables for each key\n",
    "        list_of_unique_variables = list(set([x[0] for x in X_y_zip[feature].values]))\n",
    "\n",
    "        val_dict = {}\n",
    "        for val in list_of_unique_variables:\n",
    "            # Total number of days for each unique variable\n",
    "            num_days_val = len([x[1] for x in X_y_zip[feature] if x[0] == val])\n",
    "            # Total number of days for each key (assuming it is binary (and tennis), for now)\n",
    "            num_days_val_tennis = len([x[1] for x in X_y_zip[feature] if x[0] == val and x[1] == 1])\n",
    "            num_days_val_not_tennis = num_days_val - num_days_val_tennis\n",
    "            #Calculate entropy for each unique value\n",
    "            val_entropy = calc_entropy(num_days_val_tennis/num_days_val) + calc_entropy(num_days_val_not_tennis/num_days_val)\n",
    "            # Make a list with relevant data for each unique value\n",
    "            val_list = [num_days_val, tot_num_occurences, val_entropy]\n",
    "            # Append that list to a dictionary, where the unique value is key\n",
    "            val_dict[val] = val_list\n",
    "        # Append dictionaries for unique values, to their respectively feature\n",
    "        columns_entropy[feature] = val_dict\n",
    "    return columns_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy_all_branches(data, entropy_src):\n",
    "    \"\"\"Calculates the entropy among all the branches\n",
    "    Expects a dictionary on the format \n",
    "        {'column feature': \n",
    "            {unique value: [\n",
    "                number of this value occured in the set\n",
    "                number of values in the set\n",
    "                entropy when this value occured in the set\n",
    "            ], ... }}\"\"\"\n",
    "    column_entropy_dict_full = {}\n",
    "    for column_feature in data:\n",
    "        entropy_all = 0\n",
    "        # Take each value from each 'unique value', for each 'column feature' from the inputed dictionary\n",
    "        # and calculates the entropy for each 'unique value', e.g. sunny, rainy, etc. \n",
    "        for unique_val in data[column_feature]:\n",
    "            # NOTE: As mentioned in PyDoc - assumes this format\n",
    "            num_val = data[column_feature][unique_val][0]\n",
    "            num_tot = data[column_feature][unique_val][1]\n",
    "            num_val_entropy = data[column_feature][unique_val][2]\n",
    "            entropy_all += (num_val/num_tot)*num_val_entropy\n",
    "        column_entropy_dict_full[column_feature] = entropy_all\n",
    "    \n",
    "    information_gain_dict = {}\n",
    "    for key, value in column_entropy_dict_full.items():\n",
    "        information_gain_dict[key] = randomness_reduction(entropy_src, value)\n",
    "    return information_gain_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomness_reduction(entropy_src, entropy_branch):\n",
    "    \"\"\" Calculates the reduction in randomness, aka Information Gain.\n",
    "    Takes in the entropy of the entire system, and the entropy for one branch\n",
    "    Returns the Information Gain - restricted to 3 decimals.\"\"\"\n",
    "    return (round(entropy_src - entropy_branch, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLargestInformationGain(data, target_variable):\n",
    "    \"\"\"Gets the largest IG for any given dataset (that is Pandas DataFrame)\"\"\"\n",
    "    ig_dict = calc_entropy_dataset(data, target_variable)\n",
    "    return (max(ig_dict, key=ig_dict.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'outlook'"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getLargestInformationGain(dataset_tennis_copy, 'play')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "- The best feature to pick as the one to classify on is the one with the most information (gain), i.e. highest entropy\n",
    "    - After finding the best feature, re-evaluate the entropy of each feature and again pick the one with the highest entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(X, y, impurity_measure='entropy'):\n",
    "    \"\"\"Function that learns a decision tree classifier from X and y.\n",
    "        Default impurity measure for information gain is Entropy.\"\"\"\n",
    "    # Make a leaf for each class - true \"purity\"\n",
    "    # Will implement pruning later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, tree):\n",
    "    \"\"\"Predict class label of some new data point x.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tree: (1:16:11, https://www.youtube.com/watch?v=3jl2h9hSRvc&feature=youtu.be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/41760856/most-simple-tree-data-structure-in-python-that-can-be-easily-traversed-in-both\n",
    "class Tree(object):\n",
    "    def __init__(self, data, children=None, parent=None):\n",
    "        self.data = data\n",
    "        self.children = {}\n",
    "        self.parent = parent\n",
    "\n",
    "    def add_child(self, data):\n",
    "        new_child = Tree(data, parent=self)\n",
    "        self.children.append(new_child)\n",
    "        return new_child\n",
    "\n",
    "    def is_root(self):\n",
    "        return self.parent is None\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return not self.children\n",
    "\n",
    "    \"\"\" ToString method \"\"\"\n",
    "    def __str__(self):\n",
    "        if self.is_leaf():\n",
    "            return str(self.data)\n",
    "        return '{data} [{children}]'.format(data=self.data, children=', '.join(map(str, self.children)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "1. Check data, potentially implement categorical --> numerical categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTree = Tree('foo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo\n"
     ]
    }
   ],
   "source": [
    "print(myTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAT158",
   "language": "python",
   "name": "dat158"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
