{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Implementing Decision Trees </center>\n",
    "## <center> INF283 - Project 1 </center>\n",
    "### <center> Sindre E. de Lange </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if needing to install treelib\n",
    "#! pip install treelib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To import ImpurityMeasure and DataCleaning\n",
    "sys.path.append(\"../classes/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ImpurityMeasure import *\n",
    "from DataCleaning import *\n",
    "# Utilizing the simple tree library that is \"Treelib\"\n",
    "from treelib import Node, Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_clean = DataCleaning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data in order to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mushrooms.csv', 'tennis.csv']\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = \"../csv/\"\n",
    "print(os.listdir(DATASET_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mushrooms dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mushrooms_dataset = 'mushrooms.csv'\n",
    "dataset_mushrooms = pd.read_csv(DATASET_PATH + mushrooms_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124, 23)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_mushrooms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning\n",
    "data_shrooms_no_qmarks = d_clean.removeQmarksDf(dataset_mushrooms)\n",
    "data_shrooms_fact_no_qmarks = d_clean.factorizeDf(data_shrooms_no_qmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5644, 23)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_shrooms_fact_no_qmarks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_var = 'class'\n",
    "X_no_qmarks_fact = data_shrooms_fact_no_qmarks.drop([target_var], axis=1)\n",
    "y_no_qmarks_fact = data_shrooms_fact_no_qmarks[target_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no_qmarks_fact_train, X_no_qmarks_fact_test, y_no_qmarks_fact_train, y_no_qmarks_fact_test = train_test_split(X_no_qmarks_fact, y_no_qmarks_fact, test_size=0.3, random_state=42, stratify=y_no_qmarks_fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tennis dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tennis_dataset = \"tennis.csv\"\n",
    "dataset_tennis = pd.read_csv(DATASET_PATH + tennis_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windy</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunny</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sunny</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overcast</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rainy</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rainy</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    outlook  temp humidity  windy play\n",
       "0     sunny   hot     high  False   no\n",
       "1     sunny   hot     high   True   no\n",
       "2  overcast   hot     high  False  yes\n",
       "3     rainy  mild     high  False  yes\n",
       "4     rainy  cool   normal  False  yes"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tennis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning\n",
    "data_tennis_factorized = d_clean.factorizeDf(dataset_tennis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windy</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outlook  temp  humidity  windy  play\n",
       "0        0     0         0      0     0\n",
       "1        0     0         0      1     0\n",
       "2        1     0         0      0     1\n",
       "3        2     1         0      0     1\n",
       "4        2     2         1      0     1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tennis_factorized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_var = 'play'\n",
    "X_tennis_enc = data_tennis_factorized.drop([target_var], axis=1)\n",
    "y_tennis_enc = data_tennis_factorized[target_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tennis_enc_train, X_tennis_enc_test, y_tennis_enc_train, y_tennis_enc_test = train_test_split(X_tennis_enc, y_tennis_enc, test_size=0.2, random_state=42, stratify=y_tennis_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for verifying the model *check*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBestTree(tree0_acc, tree0, tree1_acc, tree1, origin_acc, origin):\n",
    "    \"\"\" Find The Best Tree\n",
    "    \n",
    "    Finds the best tree, based on their acuraccies\n",
    "    \n",
    "    Args:\n",
    "        tree0_acc: float\n",
    "        tree0: treelib.tree.Tree\n",
    "        tree1_acc: float\n",
    "        tree1: treelib.tree.Tree\n",
    "        origin_acc: float\n",
    "        origin: treelib.tree.Tree\n",
    "        \n",
    "    Returns:\n",
    "        best_copy/origin: treelib.tree.Tree\n",
    "        copy_acc/origin_acc: float\n",
    "        string/\"origin\": String\n",
    "    \"\"\"\n",
    "    best_copy = tree0 if tree0_acc >= tree1_acc else tree1\n",
    "    return best_copy if copy_acc >= origin_acc else origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(X, y, imp_measure_alt='entropy', pruning=False, pruning_amount=0.45):\n",
    "    \"\"\" Learn\n",
    "    \n",
    "    Learns a decision tree classifier from data.\n",
    "    NOTE: Expects cleaned data, in particular categorical, discrete values (pd.factorize)\n",
    "    \n",
    "    Args:\n",
    "        X: pandas dataframe\n",
    "        y: pandas series\n",
    "        imp_measure_alt: String. How to calculate the information gain for the datasets column.\n",
    "            Either 'entropy' (standard) or 'gini'\n",
    "        pruning: Boolean. To use pruning, or not to use pruning - that is the question\n",
    "        pruning_amount: Float. Percentage distribution of the training dataset\n",
    "        \n",
    "    Returns:\n",
    "        treelib.tree.Tree. Tree classifier learned from data\n",
    "        \"\"\"\n",
    "    \n",
    "    # Divide into training and pruning dataset\n",
    "    if pruning:\n",
    "        X, X_prune, y, y_prune= train_test_split(X, y, test_size=pruning_amount, random_state=42, stratify=y)\n",
    "    \n",
    "    imp_measure = ImpurityMeasure(imp_measure_alt)\n",
    "    tree = Tree()\n",
    "    tree = make_tree(X, y, tree, imp_measure)\n",
    "    if pruning:\n",
    "        tree = prune(X_prune, y_prune, tree)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_nodes(X_prune, y_prune, tree, node):\n",
    "    \"\"\" Prune Nodes\n",
    "    \n",
    "    Checks the accuracy gain/loss obtained by each inputed node, by seeing if the accuracy in a tree with that specific node,\n",
    "    and without that specific node, when alternating its parents label. \n",
    "    \n",
    "    Args:\n",
    "        X_prune: pandas dataframe\n",
    "        y_prune: pandas series\n",
    "        tree: treelib.tree.Tree\n",
    "        node: treelib.node.Node\n",
    "        \n",
    "    Returns:\n",
    "        treelib.tree.Tree. Pruned or not pruned\n",
    "    \n",
    "    \"\"\"\n",
    "    # Get parent pointer for the node\n",
    "    parent_node_ref = node.bpointer\n",
    "    parent_node = tree.get_node(parent_node_ref)\n",
    "    \n",
    "    # Create three copies\n",
    "    orig_tree = Tree(tree.subtree(tree.root), deep=True)\n",
    "    copy_0 = Tree(orig_tree.subtree(orig_tree.root), deep=True)\n",
    "    copy_1 = Tree(orig_tree.subtree(orig_tree.root), deep=True)\n",
    "    \n",
    "    # Set up the new trees\n",
    "    copy_0 = edit_child_nodes(copy_0, parent_node, 0)\n",
    "    copy_1 = edit_child_nodes(copy_1, parent_node, 1)\n",
    "    \n",
    "    # Calculate accuracy for new trees\n",
    "    acc_orig = accuracy(X_prune, y_prune, orig_tree)\n",
    "    acc_copy_0 = accuracy(X_prune, y_prune, copy_0)\n",
    "    acc_copy_1 = accuracy(X_prune, y_prune, copy_1)\n",
    "\n",
    "    best_tree = findBestTree(acc_copy_0, copy_0, acc_copy_1, copy_0, acc_orig, orig_tree)\n",
    "    print(\"Best tree: \\n\", best_tree)\n",
    "    return best_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(X_prune, y_prune, tree):\n",
    "    \"\"\" Prune\n",
    "    \n",
    "    Prunes a tree, e.g. removes seemingly unecessary nodes while maintaing accuracy\n",
    "    \n",
    "    Args:\n",
    "        X_prune: pandas dataframe\n",
    "        y_prune: pandas series\n",
    "        tree: treelib.tree.Tree\n",
    "\n",
    "    Returns:\n",
    "        treelib.tree.Tree. Optimal tree after pruning\n",
    "    \"\"\"\n",
    "    \n",
    "    # Keep track of the original tree - to compare with the returned trees\n",
    "    tree_orig = tree\n",
    "    # A small hack in order to stop when there is no improvement\n",
    "    same_tree=False\n",
    "    \n",
    "    while not same_tree:\n",
    "        # Get an iterator of all the nodes\n",
    "        nodes_iterator = tree.all_nodes_itr()\n",
    "        # Need to loop through, reverse style\n",
    "        nodes_list_reversed =  reversed(list(tree.all_nodes_itr()))\n",
    "        for node in nodes_list_reversed:\n",
    "            # Edge case, when reached the root node\n",
    "            if (node.identifier == tree.root):\n",
    "                break\n",
    "            # When the tree is updated in prune_nodes, the node list should also be updated\n",
    "            elif not node in tree.all_nodes_itr():\n",
    "                break\n",
    "            else:\n",
    "                tree = prune_nodes(X_prune, y_prune, tree, node)\n",
    "        # No change, i.e. no improvement from pruning. \n",
    "        if checkIFDictEquals(tree.nodes, tree_orig.nodes):\n",
    "            same_tree = True\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_child_nodes(tree, node, data):\n",
    "    \"\"\" Edit Child Nodes\n",
    "    \n",
    "    Edit the data of a node in the given tree, and delete its children\n",
    "    \n",
    "    Args:\n",
    "        tree: treelib.tree.Tree\n",
    "        node: treelib.node.Node\n",
    "        data: int\n",
    "    \n",
    "    Returns:\n",
    "        treelib.tree.Tree\n",
    "    \n",
    "    node.data = data\n",
    "    # Delete its children\n",
    "    for children in node.fpointer:\n",
    "        tree.remove_node(children)\n",
    "    # Return the updated tree\n",
    "    \"\"\"\n",
    "    get_node = tree.get_node(node.identifier)\n",
    "    get_node.data = data\n",
    "    for children in get_node.fpointer:\n",
    "        tree.remove_node(children)\n",
    "    # This means there is no need to delete children - implicitly deleted\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'copy_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-158-61bc2afbe95a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_no_qmarks_fact_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_no_qmarks_fact_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimp_measure_alt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"entropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpruning\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-154-63c0a4781889>\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(X, y, imp_measure_alt, pruning, pruning_amount)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimp_measure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpruning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprune\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_prune\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_prune\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-156-d17010c3a31e>\u001b[0m in \u001b[0;36mprune\u001b[1;34m(X_prune, y_prune, tree)\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                 \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprune_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_prune\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_prune\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[1;31m# No change, i.e. no improvement from pruning.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheckIFDictEquals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree_orig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-155-d71da41b8eba>\u001b[0m in \u001b[0;36mprune_nodes\u001b[1;34m(X_prune, y_prune, tree, node)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0macc_copy_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0macuraccy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_prune\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_prune\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mbest_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfindBestTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc_copy_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_copy_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_orig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_tree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best tree: \\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_tree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbest_tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-153-ac4ccdc617d0>\u001b[0m in \u001b[0;36mfindBestTree\u001b[1;34m(tree0_acc, tree0, tree1_acc, tree1, origin_acc, origin)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \"\"\"\n\u001b[0;32m     19\u001b[0m     \u001b[0mbest_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree0\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtree0_acc\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mtree1_acc\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtree1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mbest_copy\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcopy_acc\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0morigin_acc\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0morigin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'copy_acc' is not defined"
     ]
    }
   ],
   "source": [
    "learn(X_no_qmarks_fact_train, y_no_qmarks_fact_train, imp_measure_alt=\"entropy\", pruning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(X_prune, y_prune, this_tree):\n",
    "    \"\"\" Accuracy\n",
    "    \n",
    "    Calculates the accuracy: Number of errors/total data length\n",
    "    \n",
    "    Args:\n",
    "        X_prune: pandas dataframe\n",
    "        y_prune: pandas series\n",
    "        this_tree: treelib.tree.Tree\n",
    "        \n",
    "    Returns:\n",
    "        float. corrected predicted labels / total number of labels\n",
    "    \"\"\"\n",
    "    data_len = len(y_prune)\n",
    "    correct = 0\n",
    "    for idx, val in enumerate(y_prune):\n",
    "        predicted_label = predict(X_prune.iloc[idx], this_tree)\n",
    "        if predicted_label == val:\n",
    "            correct += 1\n",
    "    return (correct/data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tree(X, y, tree, imp_measure, current_node=None):\n",
    "    \"\"\" Make Tree\n",
    "    \n",
    "    Recursive method to make a tree of the type treelib.tree.Tree\n",
    "    \n",
    "    Args:\n",
    "        X: pandas dataframe. Training features\n",
    "        y: pandas series. Target variable\n",
    "        tree: treelib.tree.Tree. Tree object to populate\n",
    "        imp_measure: String. Name of impurity measure - either 'entropy' or 'gini'\n",
    "        current_node: treelib.node.Node. Current node to build subtree from. \n",
    "        \n",
    "    Returns:\n",
    "        treelib.tree.Tree. A (populated) decision tree based on inputed datasets X and y\n",
    "    \"\"\"\n",
    "    # Edge case: tree not initialized - store whole dataset in root\n",
    "    if current_node is None:\n",
    "        # Combine data to one dataset\n",
    "        data = pd.concat([X, y], axis=1)\n",
    "        # Set root node name to something generic that is easy to get\n",
    "        # Get best split\n",
    "        root_node_tag = imp_measure.getLargestInformationGain(X, y)\n",
    "        # Make the root node, store the entire dataset\n",
    "        tree.create_node(tag=root_node_tag, data=data)\n",
    "        # Get a reference to the root node\n",
    "        current_node = tree.get_node(tree.root) \n",
    "        # Call recursive method\n",
    "        return make_children(X=X, y=y, tree=tree, imp_measure=imp_measure, current_node=current_node)\n",
    "    # Tree is initialized\n",
    "    else:\n",
    "         # Edge cases - no children to make:\n",
    "        # 1. Unique values in target variable = y\n",
    "        if len(set(y)) == 1:\n",
    "            (element, ) = set(y)\n",
    "            # Make a node of the leaf\n",
    "            # and set its single unique value as its name, and value\n",
    "            node_name = str(element)\n",
    "            data = element\n",
    "            tree.create_node(tag=node_name, data=data, parent=current_node)\n",
    "            return tree\n",
    "        # 2. No columns left in X, i.e. splitted on entire dataset\n",
    "        elif len(X.columns) == 0:\n",
    "            # Set to majority in y\n",
    "            data = y.max()\n",
    "            node_name = str(data)\n",
    "            tree.create_node(tag=node_name, data=data, parent=current_node)\n",
    "            return tree\n",
    "        else:\n",
    "            node_name = imp_measure.getLargestInformationGain(X, y)\n",
    "            # Create a new node with the name = name of best split column, and the data of its parent\n",
    "            current_node = tree.create_node(tag=node_name, data=current_node.data, parent=current_node)\n",
    "            return make_children(X=X, y=y, tree=tree, imp_measure=imp_measure, current_node=current_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_children(X, y, tree, imp_measure, current_node):\n",
    "    \"\"\" Make Children for a specific column/node in a tree\n",
    "    \n",
    "    Identifies the unique values, in a column, in a dataset, initialized node corresponding to that \n",
    "    value, and appends them to current node, i.e. their parent.\n",
    "    \n",
    "    Args:\n",
    "        X: pandas dataframe.\n",
    "        y: pandas series.\n",
    "        imp_measure: String. Name of impurity measure - either 'entropy' or 'gini'\n",
    "        current_node: Reference to a specific node, in a tree, that one wishes to populate with children\n",
    "        \n",
    "    Returns:\n",
    "        treelib.tree.Tree. Inputed tree, with appended children of current node\n",
    "    \"\"\"\n",
    "    # For each unique value in the parents column - make a child node\n",
    "    child_list = list(set(X[current_node.tag]))\n",
    "    data = pd.concat([X, y], axis=1)\n",
    "    for value in child_list:\n",
    "        node_name = str(value)\n",
    "        # Split dataset\n",
    "        data_loc = split_data(value, data, current_node.tag)\n",
    "        # Remove parent column - for children nodes\n",
    "        tree.create_node(tag=node_name, data=data_loc, parent=current_node)\n",
    "    # Need referece to each child node, therefore new loop\n",
    "    for children_node in current_node.fpointer:\n",
    "        current_node = tree.get_node(children_node)\n",
    "        X = current_node.data.drop([y.name], axis=1)\n",
    "        y = current_node.data[y.name]\n",
    "        tree = make_tree(X=X, y=y, tree=tree, imp_measure=imp_measure, current_node=current_node)\n",
    "             \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(value, data, column):\n",
    "    \"\"\" Split Data\n",
    "    \n",
    "    Splits a dataframe such that it return the rows, where the specified\n",
    "    columns value == value\n",
    "    \n",
    "    Args:\n",
    "        value: int/float/whatever, as long as it corresponds to det value in the column, in the dataframe\n",
    "        data: pandas dataframe. \n",
    "        column: String. \n",
    "        \n",
    "    Returns:\n",
    "        pandas dataframe. \n",
    "    \"\"\"\n",
    "    data_loc = data.loc[data[column] == value]\n",
    "    return data_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, tree):\n",
    "    \"\"\"Predict class label of some new data point x.\n",
    "    \n",
    "    Takes in a row of data, runs it through a tree classifier, and outputs the classifiers predicted label. \n",
    "    \n",
    "    Args:\n",
    "        x: pandas series. Data row to predict on\n",
    "        tree: treelib.tree.Tree. Tree classifier to predict the data row's label\n",
    "    \n",
    "    Returns:\n",
    "        int. Assuming the dataset is factorized, otherwise it will be whatever the values are in the target variable series.\n",
    "    \"\"\"\n",
    "    \n",
    "    current_node = tree.get_node(tree.root)\n",
    "    classification_value = getClassificationLabel(x=x, tree=tree, current_node=current_node)\n",
    "    return classification_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassificationLabel(x, tree, current_node):\n",
    "    \"\"\" Get Classification Label\n",
    "    \n",
    "    Recursive method that uses the inputed data row 'x' to traverse the decision tree,\n",
    "    find the leaf that corresponds to 'x's data, and return its label/data\n",
    "    \n",
    "    Args:\n",
    "        x: pandas series. Data row to predict on\n",
    "        tree: treelib.tree.Tree. Tree classifier to predict the data row's label\n",
    "        current_node: treelib.node.Node. Current node to check if one of its children is the correct leaf\n",
    "    \n",
    "    Returns:\n",
    "        int. Assuming the dataset is factorized, otherwise it will be whatever the values are in the target variable series.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Current node's name is the name of the column that is (presumably) best to split on\n",
    "    # Note - after a small change to the tree setup, we have to use the parents\n",
    "    # name, if one is at a node that represents a unique value from parents column\n",
    "    current_node_tag = current_node.tag\n",
    "    if current_node_tag.isdigit():\n",
    "        # Get parents name \n",
    "        parent = tree.get_node(current_node.bpointer)\n",
    "        split_column = parent.tag\n",
    "    else:\n",
    "        split_column = current_node.tag\n",
    "    # Find the children node which has the same value, in the same column\n",
    "    correct_children_node = None\n",
    "    # Find the column in the inputed dataset = x, and get its value\n",
    "    val_x = x.get(split_column)\n",
    "    # Hacky, but does not work to return inside a for loop, and no time to change logic\n",
    "    correct_label = None\n",
    "    # Loop through the children of current node\n",
    "    for node_children in current_node.fpointer:\n",
    "        # node_children is only identifier to children - need to get the actual references to those children\n",
    "        current_children_node = tree.get_node(node_children)\n",
    "        # Check if children node is leaf - return its data = classification label\n",
    "        if current_children_node.is_leaf():\n",
    "            correct_label = current_children_node.data\n",
    "            break\n",
    "        # If a node's column = parents tag contains val_x --> correct child node\n",
    "        elif val_x in current_children_node.data[split_column].values:\n",
    "            correct_children_node = current_children_node\n",
    "            break\n",
    "        else:\n",
    "            #There is no child node with that specific value in that column\n",
    "            # Set label to majority in current node\n",
    "            target_variabel = current_node.data.drop(columns=x.index, axis=1)\n",
    "            # So hacky I might throw up, but when I get a df, not a series.. \n",
    "            correct_label = getMostFrequentValueFromPandasDFThatShouldBeASeries(target_variabel)\n",
    "          \n",
    "    if correct_label is None:\n",
    "        return getClassificationLabel(x=x, tree=tree, current_node=correct_children_node)\n",
    "    \n",
    "    return correct_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMostFrequentValueFromPandasDFThatShouldBeASeries(df):\n",
    "    \"\"\" Get The Most Frequent Value From a Panas Dataframe, That Probably Should've Been a Pandas Series\n",
    "    \n",
    "    Was having trouble with accessing the target variable column in a data frame, because it was returned as \n",
    "    a pandas dataframe. This method takes a Pandas Dataframe (1D), accesses it's single column name, and \n",
    "    returns the value of the most frequent value, in that column.\n",
    "    \n",
    "    Args:\n",
    "        df: pandas dataframe.\n",
    "        \n",
    "    Returns:\n",
    "        int/float/whatever that is stored in the target variable, that appears most frequently. \n",
    "    \n",
    "    \"\"\"\n",
    "    column_name = df.columns.values[0]\n",
    "    return list((df[column_name].value_counts()).index)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isLeaf(node):\n",
    "    \"\"\" Is a Leaf\n",
    "    \n",
    "    Check whether a specific node should be a leaf or not. \n",
    "    Currently not in use, but seemingly ok to have, if I were to continue with this project. \n",
    "    \n",
    "    Args:\n",
    "        node: treelib.node.Node\n",
    "        \n",
    "    Returns:\n",
    "        boolean    \n",
    "    \"\"\"\n",
    "    if len(node.fpointer) == 0:\n",
    "        return True\n",
    "    elif len(set(node.data['play'])) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkIFDictEquals(dict1, dict2):\n",
    "    \"\"\" Check if two dictionaries are equal\n",
    "    \n",
    "    A somewhat hacky way of comparing two dictionaries. Checks \"equalness\" by seeing if the two dictionaries have \n",
    "    the same amount of keys. \n",
    "    This works (somewhat) for treelib, in this context, because amount of keys = amount of nodes. \n",
    "    If two trees have exactly the same amount of nodes, then there is a pretty good chance they are the same. \n",
    "    \n",
    "    Args:\n",
    "        dict1: dictionary\n",
    "        dict1: dictionary\n",
    "        \n",
    "    Returns:\n",
    "        Boolean.     \n",
    "    \"\"\"\n",
    "    dict1_keys_len = len(dict1.keys())\n",
    "    dict2_keys_len = len(dict2.keys())\n",
    "    return dict1_keys_len == dict2_keys_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mushrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mushroom_tree = learn(X_no_qmarks_fact_train, y_no_qmarks_fact_train)\n",
    "print(accuracy(X_no_qmarks_fact_test, y_no_qmarks_fact_test, mushroom_tree))\n",
    "print(mushroom_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_no_qmarks_fact_train, y_no_qmarks_fact_train)\n",
    "print(clf.score(X_no_qmarks_fact_test, y_no_qmarks_fact_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tennis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlook\n",
      "├── 0\n",
      "│   └── temp\n",
      "│       ├── 0\n",
      "│       │   └── 0\n",
      "│       └── 1\n",
      "│           └── 1\n",
      "├── 1\n",
      "│   └── 1\n",
      "└── 2\n",
      "    └── windy\n",
      "        ├── 0\n",
      "        │   └── 1\n",
      "        └── 1\n",
      "            └── 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tennis_tree = learn(X_tennis_enc_train, y_tennis_enc_train)\n",
    "print(tennis_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "tennis_acc = accuracy(X_tennis_enc_test, y_tennis_enc_test, tennis_tree)\n",
    "print(tennis_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_tennis_enc_train, y_tennis_enc_train)\n",
    "print(clf.score(X_tennis_enc_test, y_tennis_enc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Not surprising considering the amount of data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAT158",
   "language": "python",
   "name": "dat158"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
