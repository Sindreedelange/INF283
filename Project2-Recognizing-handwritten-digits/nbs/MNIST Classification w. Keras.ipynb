{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducible results\n",
    "random_state = 42\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(one_hot_enc=True, reshape=False, train_val_test=False):\n",
    "    DATA_PATH = \"../data/\"\n",
    "    file_list = os.listdir(DATA_PATH)\n",
    "    images_path = file_list[0]\n",
    "    labels_path = file_list[1]\n",
    "    images_path_full = os.path.join(DATA_PATH + images_path)\n",
    "    labels_path_full = os.path.join(DATA_PATH + labels_path)\n",
    "    X = pd.read_csv(images_path_full)\n",
    "    if reshape:\n",
    "        X = X.values.astype('float32')\n",
    "        # Normalize data\n",
    "        X = X / 255\n",
    "        # Reshape for cnn \n",
    "        X = X.reshape([-1, 28, 28, 1]).astype('float32')\n",
    "    else:\n",
    "        # Normalize data\n",
    "        X = X / 255\n",
    "    y = pd.read_csv(labels_path_full)\n",
    "    # Encode labels\n",
    "    if one_hot_enc:\n",
    "        encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "        y = encoder.fit_transform(y)\n",
    "    # Divide into train and test set \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "    if train_val_test:\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=random_state)\n",
    "        return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "    else:\n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_shapes_val(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    print(\"X_train_nn: \", X_train.shape)\n",
    "    print(\"X_val_nn: \", X_val.shape)\n",
    "    print(\"X_test_nn: \", X_test.shape)\n",
    "    print(\"y_train_nn: \", y_train.shape)\n",
    "    print(\"y_val_nn: \", y_val.shape)\n",
    "    print(\"y_test_nn: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_shapes_nval(X_train, X_test, y_train, y_test):\n",
    "    print(\"X_train_nn: \", X_train.shape)\n",
    "    print(\"X_test_nn: \", X_test.shape)\n",
    "    print(\"y_train_nn: \", y_train.shape)\n",
    "    print(\"y_test_nn: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder_path = \"../models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Forward Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nn, X_val_nn, X_test_nn, y_train_nn, y_val_nn, y_test_nn = get_data(train_val_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_nn = \"MNIST_nn\"\n",
    "model_name_ext_nn = \".hdf5\"\n",
    "full_path_nn = model_folder_path + model_name_nn + model_name_ext_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model_nn = keras.models.load_model(full_path_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "\n",
    "# Model compile\n",
    "adam = Adam(lr=1e-3)\n",
    "metrics = ['accuracy']\n",
    "loss = 'categorical_crossentropy'\n",
    "\n",
    "# Model architecture\n",
    "regularizer_l2 = regularizers.l2(0.01)\n",
    "\n",
    "# Model fit\n",
    "epochs = 12\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_nn:  (39199, 784)\n",
      "X_val_nn:  (16800, 784)\n",
      "X_test_nn:  (14000, 784)\n",
      "y_train_nn:  (39199, 10)\n",
      "y_val_nn:  (16800, 10)\n",
      "y_test_nn:  (14000, 10)\n"
     ]
    }
   ],
   "source": [
    "print_data_shapes_val(X_train_nn, X_val_nn, X_test_nn, y_train_nn, y_val_nn, y_test_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = Sequential()\n",
    "model_nn.add(Dense(256, input_dim=784, activation='relu', kernel_regularizer=regularizer_l2))\n",
    "model_nn.add(Dense(128, activation='relu'))\n",
    "model_nn.add(Dense(64, activation='relu'))\n",
    "model_nn.add(Dense(32, activation='relu'))\n",
    "model_nn.add(Dense(16, activation='relu'))\n",
    "model_nn.add(Dense(8, activation='relu', kernel_regularizer=regularizer_l2))\n",
    "model_nn.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn.compile(loss=loss, optimizer=adam, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39199 samples, validate on 16800 samples\n",
      "Epoch 1/12\n",
      "39199/39199 [==============================] - 6s 160us/step - loss: 1.0513 - acc: 0.8305 - val_loss: 0.5049 - val_acc: 0.9298\n",
      "Epoch 2/12\n",
      "39199/39199 [==============================] - 6s 148us/step - loss: 0.4660 - acc: 0.9308 - val_loss: 0.4564 - val_acc: 0.9242\n",
      "Epoch 3/12\n",
      "39199/39199 [==============================] - 6s 148us/step - loss: 0.3904 - acc: 0.9439 - val_loss: 0.4037 - val_acc: 0.9355\n",
      "Epoch 4/12\n",
      "39199/39199 [==============================] - 6s 149us/step - loss: 0.3471 - acc: 0.9494 - val_loss: 0.3405 - val_acc: 0.9521\n",
      "Epoch 5/12\n",
      "39199/39199 [==============================] - 6s 151us/step - loss: 0.3184 - acc: 0.9534 - val_loss: 0.3363 - val_acc: 0.9489\n",
      "Epoch 6/12\n",
      "39199/39199 [==============================] - 7s 182us/step - loss: 0.2880 - acc: 0.9583 - val_loss: 0.3093 - val_acc: 0.9520\n",
      "Epoch 7/12\n",
      "39199/39199 [==============================] - 8s 209us/step - loss: 0.2767 - acc: 0.9582 - val_loss: 0.2864 - val_acc: 0.9565\n",
      "Epoch 8/12\n",
      "39199/39199 [==============================] - 8s 198us/step - loss: 0.2598 - acc: 0.9610 - val_loss: 0.3238 - val_acc: 0.9423\n",
      "Epoch 9/12\n",
      "39199/39199 [==============================] - 8s 216us/step - loss: 0.2526 - acc: 0.9600 - val_loss: 0.2685 - val_acc: 0.9578\n",
      "Epoch 10/12\n",
      "39199/39199 [==============================] - 8s 205us/step - loss: 0.2388 - acc: 0.9630 - val_loss: 0.2436 - val_acc: 0.9618\n",
      "Epoch 11/12\n",
      "39199/39199 [==============================] - 13s 334us/step - loss: 0.2325 - acc: 0.9638 - val_loss: 0.2499 - val_acc: 0.9598\n",
      "Epoch 12/12\n",
      "39199/39199 [==============================] - 11s 291us/step - loss: 0.2251 - acc: 0.9654 - val_loss: 0.2288 - val_acc: 0.9642\n",
      "14000/14000 [==============================] - 1s 88us/step\n"
     ]
    }
   ],
   "source": [
    "start_nn = time.time()\n",
    "history_nn = model_nn.fit(X_train_nn, y_train_nn, validation_data=(X_val_nn, y_val_nn), epochs=epochs, batch_size=batch_size)\n",
    "end_nn = time.time()\n",
    "scores_nn = model_nn.evaluate(X_test_nn, y_test_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_nn = round(end_nn - start_nn, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.23473759935583388, 0.9642142857142857] \n",
      " Training time:  94.46  seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Scores: \", scores_nn, \"\\n Training time: \", tot_nn, \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Can see that the model is somewhat overfitting - Will try to implement *Regularizer*\n",
    "<br>\n",
    "This resulted in a loss in accuracy, but there is a trade off between accuracy and overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_dict['(Standard) Neural Network'] = {'accuracy': scores_nn[1], 'time': tot_nn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.models.save_model(model_nn, full_path_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn, X_val_cnn, X_test_cnn, y_train_cnn, y_val_cnn, y_test_cnn = get_data(one_hot_enc=False, reshape=True, train_val_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cnn = np_utils.to_categorical(y_train_cnn)\n",
    "y_val_cnn = np_utils.to_categorical(y_val_cnn)\n",
    "y_test_cnn = np_utils.to_categorical(y_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_nn:  (39199, 28, 28, 1)\n",
      "X_val_nn:  (16800, 28, 28, 1)\n",
      "X_test_nn:  (14000, 28, 28, 1)\n",
      "y_train_nn:  (39199, 10)\n",
      "y_val_nn:  (16800, 10)\n",
      "y_test_nn:  (14000, 10)\n"
     ]
    }
   ],
   "source": [
    "print_data_shapes_val(X_train_cnn, X_val_cnn, X_test_cnn, y_train_cnn, y_val_cnn, y_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_cnn = \"MNIST_cnn\"\n",
    "model_name_ext_cnn = \".hdf5\"\n",
    "full_path_cnn = model_folder_path + model_name_cnn + model_name_ext_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model_cnn = keras.models.load_model(full_path_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = Sequential()\n",
    "model_cnn.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_cnn.add(Dropout(0.4))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(128, activation='relu'))\n",
    "model_cnn.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39199 samples, validate on 16800 samples\n",
      "Epoch 1/4\n",
      "39199/39199 [==============================] - 20s 515us/step - loss: 0.1929 - acc: 0.9382 - val_loss: 0.0729 - val_acc: 0.9785\n",
      "Epoch 2/4\n",
      "39199/39199 [==============================] - 21s 543us/step - loss: 0.0611 - acc: 0.9799 - val_loss: 0.0652 - val_acc: 0.9789\n",
      "Epoch 3/4\n",
      "39199/39199 [==============================] - 25s 642us/step - loss: 0.0438 - acc: 0.9863 - val_loss: 0.0514 - val_acc: 0.9842\n",
      "Epoch 4/4\n",
      "39199/39199 [==============================] - 24s 607us/step - loss: 0.0347 - acc: 0.9888 - val_loss: 0.0468 - val_acc: 0.9864\n",
      "14000/14000 [==============================] - 4s 306us/step\n"
     ]
    }
   ],
   "source": [
    "start_cnn = time.time()\n",
    "history_cnn = model_cnn.fit(X_train_cnn, y_train_cnn, validation_data=(X_val_cnn, y_val_cnn), epochs=4, batch_size=200)\n",
    "end_cnn = time.time()\n",
    "scores_cnn = model_cnn.evaluate(X_test_cnn, y_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_cnn = round(end_cnn - start_cnn, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.04565956243426938, 0.9862142857142857] \n",
      " Training time:  90.88  seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Scores: \", scores_cnn, \"\\n Training time: \", tot_cnn, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_dict['Convolutional Neural Network'] = {'accuracy': scores_cnn[1], 'time': tot_cnn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "keras.models.save_model(model_cnn, full_path_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_nn:  (55999, 784)\n",
      "X_test_nn:  (14000, 784)\n",
      "y_train_nn:  (55999, 10)\n",
      "y_test_nn:  (14000, 10)\n"
     ]
    }
   ],
   "source": [
    "print_data_shapes_nval(X_train_rf, X_test_rf, y_train_rf, y_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_rf = \"MNIST_Random_Forest\"\n",
    "model_name_ext_rf = \".pickle.dat\"\n",
    "full_path_rf = model_folder_path + model_name_rf + model_name_ext_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# random_f_clf = pickle.load(open(full_path_rf), \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_f_clf = RandomForestClassifier(n_estimators=50,\n",
    "                                     n_jobs = 2,\n",
    "                                     random_state=random_state)\n",
    "start_rf = time.time()\n",
    "random_f_clf.fit(X_train_rf, y_train_rf)\n",
    "end_rf = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_rf = round(end_rf - start_rf, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = random_f_clf.predict(X_test_rf)\n",
    "scores_rf = accuracy_score(y_test_rf, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  0.8957857142857143 \n",
      " Training time:  14.08  seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Scores: \", scores_rf, \"\\n Training time: \", tot_rf, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_dict['Random Forest'] = {'accuracy': scores_rf, 'time': tot_rf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "pickle.dump(random_f_clf, open(full_path_rf, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needing to install xgboost (using conda)\n",
    "# ! conda install py-xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb = get_data(one_hot_enc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_nn:  (55999, 784)\n",
      "X_test_nn:  (14000, 784)\n",
      "y_train_nn:  (55999, 1)\n",
      "y_test_nn:  (14000, 1)\n"
     ]
    }
   ],
   "source": [
    "print_data_shapes_nval(X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_xgb = \"MNIST_XGBoost\"\n",
    "model_name_ext_xgb = \".pickle.dat\"\n",
    "full_path_xgb = model_folder_path + model_name_xgb + model_name_ext_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: If you want to save time - load the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "# optim_est_xgb = pickle.load(open(full_path_xgb), \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'gamma': [0.5, 2],\n",
    "        'subsample': [0.6, 1.0],\n",
    "        'colsample_bytree': [0.6, 1.0],\n",
    "        'max_depth': [3, 5],\n",
    "        'n_estimators': [5, 10]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fun to try with more parameters, but my poor CPU cannot take any more.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer: This takes a lot of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "xgb_clf = XGBClassifier()\n",
    "rs = GridSearchCV(xgb_clf,\n",
    "                  params,\n",
    "                  cv=2,\n",
    "                  scoring=\"accuracy\",\n",
    "                  n_jobs=1,\n",
    "                  verbose=2)\n",
    "start_xgb = time.time()\n",
    "rs.fit(X_train_xgb, y_train_xgb.values.ravel())\n",
    "end_xgb = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_est_xgb = rs.best_estimator_\n",
    "print(optim_est_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_xgb = round(end_xgb - start_xgb, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = optim_est_xgb.predict(X_test_xgb)\n",
    "scores_xgb = accuracy_score(y_test_xgb, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  0.9046428571428572 \n",
      " Training time:  2467.44  seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Scores: \", scores_xgb, \"\\n Training time: \", tot_xgb, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_dict['XGBoost'] = {'accuracy': scores_xgb, 'time': tot_xgb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(optim_est_xgb, open(full_path_xgb, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Standard) Neural Network {'accuracy': 0.9585714285714285, 'time': 67.99}\n",
      "Convolutional Neural Network {'accuracy': 0.9859285714285714, 'time': 86.85}\n",
      "Random Forest {'accuracy': 0.8957857142857143, 'time': 14.08}\n",
      "XGBoost {'accuracy': 0.9046428571428572, 'time': 2467.44}\n"
     ]
    }
   ],
   "source": [
    "for k, v in classifiers_dict.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-d34c95283888>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifiers_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifiers_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'g'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\dat158\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2773\u001b[0m                       mplDeprecation)\n\u001b[0;32m   2774\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2775\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2776\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2777\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dat158\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1865\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1867\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dat158\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2281\u001b[0m                 \u001b[0medgecolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2282\u001b[0m                 \u001b[0mlinewidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2283\u001b[1;33m                 \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'_nolegend_'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2284\u001b[0m                 )\n\u001b[0;32m   2285\u001b[0m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dat158\\lib\\site-packages\\matplotlib\\patches.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, xy, width, height, angle, **kwargs)\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_x1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_x0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_width\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_height\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mangle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mangle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'dict'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAEAJJREFUeJzt3X+s3XV9x/HnyxaEIEOFi1HaSZcVoXMIckUdU1ExARPpyOqEoBM0dslkuMiW4XToYDjFoJkTf3QbAY2KYPzRORQdAhpGWW8FKgW7NB2OO5gURTKGCtX3/jjfwuFw2/u97Sm1H5+PpOF8v9/P+Z7PuW2e93u+55wvqSokSW150q6egCRp/Iy7JDXIuEtSg4y7JDXIuEtSg4y7JDVo1rgnuTjJPUlu3cr2JPlwkg1J1iZ5/vinKUmaiz5H7pcAx29j+wnA4u7PcuBjOz4tSdKOmDXuVfUt4EfbGLIU+GQNrAKemuSZ45qgJGnu5o9hHwcBdw4tT3fr7h4dmGQ5g6N79tlnn6MOPfTQMTy8JP3qWLNmzb1VNTHbuHHEPTOsm/GaBlW1AlgBMDk5WVNTU2N4eEn61ZHk+33GjePTMtPAwqHlBcBdY9ivJGk7jSPuK4E/7D418yLg/qp63CkZSdITZ9bTMkk+CxwLHJBkGng3sAdAVX0cuBJ4NbABeBA4fWdNVpLUz6xxr6pTZtlewFvHNiNJ0g7zG6qS1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1CDjLkkNMu6S1KBecU9yfJL1STYkOXuG7b+e5JokNyVZm+TV45+qJKmvWeOeZB5wEXACsAQ4JcmSkWHvAi6vqiOBk4GPjnuikqT++hy5Hw1sqKqNVfUQcBmwdGRMAb/W3d4PuGt8U5QkzVWfuB8E3Dm0PN2tG/Ye4PVJpoErgT+ZaUdJlieZSjK1adOm7ZiuJKmPPnHPDOtqZPkU4JKqWgC8GvhUksftu6pWVNVkVU1OTEzMfbaSpF76xH0aWDi0vIDHn3Z5M3A5QFXdAOwFHDCOCUqS5q5P3FcDi5MsSrIngzdMV46M+S/glQBJDmMQd8+7SNIuMmvcq2ozcAZwFXA7g0/FrEtybpITu2FnAW9JcgvwWeC0qho9dSNJeoLM7zOoqq5k8Ebp8Lpzhm7fBhwz3qlJkraX31CVpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqUK+4Jzk+yfokG5KcvZUxf5DktiTrknxmvNOUJM3F/NkGJJkHXAS8CpgGVidZWVW3DY1ZDLwDOKaq7kty4M6asCRpdn2O3I8GNlTVxqp6CLgMWDoy5i3ARVV1H0BV3TPeaUqS5qJP3A8C7hxanu7WDTsEOCTJ9UlWJTl+ph0lWZ5kKsnUpk2btm/GkqRZ9Yl7ZlhXI8vzgcXAscApwD8meerj7lS1oqomq2pyYmJirnOVJPXUJ+7TwMKh5QXAXTOM+XJVPVxV/wmsZxB7SdIu0Cfuq4HFSRYl2RM4GVg5MuZLwMsBkhzA4DTNxnFOVJLU36xxr6rNwBnAVcDtwOVVtS7JuUlO7IZdBfwwyW3ANcCfV9UPd9akJUnblqrR0+dPjMnJyZqamtoljy1Ju6ska6pqcrZxfkNVkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhrUK+5Jjk+yPsmGJGdvY9yyJJVkcnxTlCTN1axxTzIPuAg4AVgCnJJkyQzj9gXOBG4c9yQlSXPT58j9aGBDVW2sqoeAy4ClM4w7D7gA+OkY5ydJ2g594n4QcOfQ8nS37hFJjgQWVtVXtrWjJMuTTCWZ2rRp05wnK0nqp0/cM8O6emRj8iTgQ8BZs+2oqlZU1WRVTU5MTPSfpSRpTvrEfRpYOLS8ALhraHlf4LnAtUnuAF4ErPRNVUnadfrEfTWwOMmiJHsCJwMrt2ysqvur6oCqOriqDgZWASdW1dROmbEkaVazxr2qNgNnAFcBtwOXV9W6JOcmOXFnT1CSNHfz+wyqqiuBK0fWnbOVscfu+LQkSTvCb6hKUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1qFfckxyfZH2SDUnOnmH725PclmRtkquTPHv8U5Uk9TVr3JPMAy4CTgCWAKckWTIy7CZgsqoOBz4PXDDuiUqS+utz5H40sKGqNlbVQ8BlwNLhAVV1TVU92C2uAhaMd5qSpLnoE/eDgDuHlqe7dVvzZuCrM21IsjzJVJKpTZs29Z+lJGlO+sQ9M6yrGQcmrwcmgQ/MtL2qVlTVZFVNTkxM9J+lJGlO5vcYMw0sHFpeANw1OijJccA7gZdV1c/GMz1J0vboc+S+GlicZFGSPYGTgZXDA5IcCXwCOLGq7hn/NCVJczFr3KtqM3AGcBVwO3B5Va1Lcm6SE7thHwCeAlyR5OYkK7eyO0nSE6DPaRmq6krgypF15wzdPm7M85Ik7QC/oSpJDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDTLuktQg4y5JDeoV9yTHJ1mfZEOSs2fY/uQkn+u235jk4HFPVJLU36xxTzIPuAg4AVgCnJJkyciwNwP3VdVvAh8C3j/uiUqS+utz5H40sKGqNlbVQ8BlwNKRMUuBS7vbnwdemSTjm6YkaS7m9xhzEHDn0PI08MKtjamqzUnuB/YH7h0elGQ5sLxbfCDJ+u2ZtLSTHcDIv13pl8iz+wzqE/eZjsBrO8ZQVSuAFT0eU9plkkxV1eSunoe0I/qclpkGFg4tLwDu2tqYJPOB/YAfjWOCkqS56xP31cDiJIuS7AmcDKwcGbMSeGN3exnwzap63JG7JOmJMetpme4c+hnAVcA84OKqWpfkXGCqqlYC/wR8KskGBkfsJ+/MSUs7macOtduLB9iS1B6/oSpJDTLuktQg465HJNk7yXVJ5iV5UpIPJ7k1yXeTrE6yqBv3l2N+3Ad28P6nJflId/uMJKdvZdx7kjyY5MBxPXbP+R2b5CtbWV9JXjO07itJjp1lf6cledZOmOclSZaNe7/aNYy7hr0J+EJV/Rx4HfAs4PCq+m3gJODH3bixxn0uMrCtf7cXA2duY/u9wFnjndUjHwHeHtPAO+d4n9MY/N2MzQ7MX7+kjLuGnQp8ubv9TODuqvoFQFVNV9V9Sd4H7J3k5iSfBkjypSRrkqzrvoVMt/6BJOcnuSXJqiTP6NYvSnJD92rgvKHxT0lydZLvdK8WlnbrD05ye5KPAt8BFiY5Pcl/JLkOOGbLPqrqQeCOJEdv5TleDLwuydNHNyR5fZJ/757bJ7rrKj3m6D7JsiSXdLcvSfLBJNcA709ydJJ/S3JT99/n9PiZ3wLcn+RVM8znqO6V1JokVyV5ZndkPQl8upvny5J8oRu/NMlPkuyZZK8kG7v1R3Q//7VJvpjkad36a5O8t/sZvm3ksc/rnp+N2E35FycAuu8w/EZV3dGtuhx4TReQC5McCVBVZwM/qaojqurUbuybquooBtE5M8n+3fp9gFVV9TzgW8BbuvV/B3ysql4A/M/QNH4KnFRVzwdeDlyYPHKNoucAn6yqI4GHgL9mEPVXMbig3bAp4CVbeaoPMAj8aMwOY/Bq5ZiqOgL4OYNfdrM5BDiuqs4Cvge8tJvjOcB7e9wf4G+Ad43MZw/g74Fl3c/2YuD8qvo8g+d3ajfP64Eju7u9BLgVeAGDS4Tc2K3/JPAXVXU48F3g3UMP9dSqellVXTj02BcABwKnb/nlrt2PL8W0xQE8etqFqprujjxf0f25Oslrq+rqGe57ZpKTutsLgcXADxlEeMu55jUMQgyDKP9+d/tTPHoV0QDvTfJS4BcMrln0jG7b96tqVXf7hcC1VbUJIMnnGER2i3uAQ7fxXD8M3JzkwqF1rwSOAlZ3v0/27vYzmyu601gw+Gb2pUkWM7j8xh497k9VfTsJSYZ/IT0HeC7wjW4+84C7Z7jv5gwutX0Yg4v8fRB4aTf+20n2YxDw67q7XApcMbSLz43s8q+AG6tqOdqtGXdt8RNgr+EVVfUz4KvAV5P8APg94DFx7978Ow54cVU9mOTaof08PPRN5Z/z2H9vM33B4lRgAjiqqh5OcsfQvv5vZOy2vqCxV/d8ZlRVP07yGeCPh58KcGlVvWOmu4zse9jwvM4DrqmqkzL4fxpcu405jjqfwbn3zUPzWVdVL+5x328zuCT3w8C/ApcwiPuf9bjv6M91NXBUkqdXlZcQ2Y15WkYAVNV9wLwkewEkef6WT2R0510PB77fDX+4O20Ag6PV+7qwHwq8qMfDXc+j32IePvWxH3BPF/aXs/Wr390IHJtk/24erx3ZfgiD0xPb8kHgj3j0F87VwLJ0n6RJ8vQkWx7/B0kO634OJz1+V4+Z/393t0+b5fEfo6q+DjwNeF63aj0wkeTF3Xz2SPJb3bb/BfYduvu3gD8FbuhezezP4JXLuqq6H7hv6FXBG4Dr2LqvAe8D/iXJvtsYp19yxl3Dvg78bnf7QOCfk9wKrGVwRPmRbtsKYG33hurXgPlJ1jI4cl3F7N4GvDXJagZB3OLTwGSSKQbR/95Md66qu4H3ADcwOFL9zsiQY7r1W1VV9wJfBJ7cLd/G4Lz317vn8g0GbyoDnM3g9NI3meHUyJALgL9Ncj2DI+e5Op/Bhfno/t8Jyxi8UXsLcDPwO924S4CPd++H7M3gl90zGEQeBn9fa4deNb0R+ED3vI4Azt3WJKrqCuAfgJXd/rUb8vIDekT3punbq+oNu3ou26uF5yCNg0fuekRV3QRcs+UjgLupAxi8KSj9SvPIXZIa5JG7JDXIuEtSg4y7JDXIuEtSg4y7JDXo/wE1wswwr0jfsgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(list(classifiers_dict.keys()), classifiers_dict.values(), color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAT158",
   "language": "python",
   "name": "dat158"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
